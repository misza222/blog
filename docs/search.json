[
  {
    "objectID": "posts/new_programming_paradigm.html",
    "href": "posts/new_programming_paradigm.html",
    "title": "Michał Pawłowski",
    "section": "",
    "text": "Software 2.0 as a new programming paradigm.\n\n- for certain class of problems\n- compexity\n- bias in data\n\nsee https://www.youtube.com/watch?v=orY5aLMDU-I"
  },
  {
    "objectID": "posts/how_to_read_papers/index.html",
    "href": "posts/how_to_read_papers/index.html",
    "title": "How to read papers?",
    "section": "",
    "text": "Andrew Ng gave an career advice lecture at Stanford in 2019 where he also mentioned how to read academic papers.\nRead it taking multiple passes through the paper:\n\nTitle + Abstract + Figures\nIntro + Conclusions + Figures + Skim rest\nRead text but skip math\nRead all of it but skip what doesn’t make sense\n\nwhich boils down to:\nGo from efficient and high information content first and dig into the harder bits gradually\nSome of the questions to keep in mind during the process (and to decide whether to go to the next step):\n\nWhat did authors try to acomplish?\nWhat are the key elements of the approach?\nWhat can you use yourself?\nWhat other references do you want to follow?\n\nIt is worth watching, as it also sumarizes the process of creating and reviewing the paper to give rationale for that process."
  },
  {
    "objectID": "posts/ak_playlist/index.html",
    "href": "posts/ak_playlist/index.html",
    "title": "Michał Pawłowski",
    "section": "",
    "text": "from IPython.display import IFrame\nIFrame('https://www.youtube.com/embed/videoseries?si=fzJ6AaBxySFQtgtS&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ', title=\"YouTube video player\", frameborder=\"0\", allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\", width=700, height=350)"
  },
  {
    "objectID": "posts/synthetic_vision_training/index.html",
    "href": "posts/synthetic_vision_training/index.html",
    "title": "Training vision models on synthetic images",
    "section": "",
    "text": "What if we’ll be able to train vision NN model with 0, nil, nada real world examples? But we have to train on something, right? Surely training on a pure noise won’t give us anything useful? See CNN-Rand or StyleGAN-Random (both initialized randomly, no training whatsoever) below and you will be surprised! Moreover if we construct synthetic images that are closer to the real world images, can we train on it with some positive outcomes? But then how well can we train? Paper presented below tried to answer that question.\nUnless tagged otherwise, ideas in this blog post come from the Learning to See by Looking at Noise paper, recorded presentation by Antonio Torralba who is one of the authors and presentation by Rosanne Liu during Deep Learning: Classics and Trends.\n\nRationale for this exercise\nModels are more and more reliant on data. CLIP need 400 000 000 images to be trained well for example. What if we could build a synthetic dataset to train? Why:\n\nyou don’t have access to data\ncheaper to maintain the data\nmaybe generating a good synthetic dataset can be better than real data (no human bias for example)\n\n\n\nTask\nThe training objective is classification of ImageNet-100 images.\n\n\nTraining procedure\nIt is done in 2 stages:\n\nThe “base” network is trained using unsupervised contrastive learning (simplifying it is done by identifying if images are the same or come from the same source image with transformations applied; details of the specific approach used in the paper)\nFinal layer (but could be layers I think) are trained briefly on actual data to create a head of the model (to me it was not clear reading the paper but see this training script by authors)\n\nTechnicalities derived from the code:\n\nunsupervised part (1):\n\nmodel parameters: TBD\nepochs: 200\ntime: TBD (most expensive part)\n\nsupervised part (2):\n\nmodel parameters: TBD\nepochs: 100\ntime: TBD (but as it is training just single fc layer, this will be cheap)\n\n\n\n\nDatasets\nSee this image of datasets used in this experiment which are referred blow on the benchmark graph.\n\n\n\nResults\n\nBlack bars are different baselines and coloured bars represent various sythetic datasets. About 20% is a difference between the best model trained on actual images and best model pre-trained on synthetic images. The surprising bit is, that randomly initialized networks can give much better than chance results (and random choice is 1% as we have 100 classes): CNN - Rand and StyleGAN - Random. The explanation was, that last fully connected layer will give some performance boost, but Antonio in his video also mentions that even some of those randomly initialized “features must be useful to some degree”. So for example in CNN some of the filters extract information that is then used by linear layer to reason upon.\n\n\nMy Conclusions\nCan this approach democratize access to data, as currently data collection and maintenance is being more and more concentrated? It looks like it, but for now it comes at the cost of performance. There was also a lot of laughter during the Antonios presentation about Stable Diffusion, so I have to add that: what would be the result if data was generated by SD model?"
  },
  {
    "objectID": "posts/optuna_notes/index.html",
    "href": "posts/optuna_notes/index.html",
    "title": "Optuna is hot on Kaggle",
    "section": "",
    "text": "While doing HF RL course I bumped into Optuna, then I’ve noticed that ppl do it on Kaggle a lot - this is like a badge of honor for a package if it is being used on a top ML competition site ergo it is worth learning!\nSome vocab to get started:\n\nobjective(trial) function - function to optimize\ntrial - a single test, also an object passed to the objective function\nstudy - a set of trial at the end of which you get a suggestion of parameters to use\nparameter - parameter to optimize\nsetting initial values for parameters to optimize:\n\noptuna.trial.Trial.suggest_categeorical(‘name’, [‘list’])\noptuna.trial.Trial.suggest_int(‘name’, min, max)\noptuna.trial.Trial.suggest_float(‘name’, min, max)\n\n\nHere is a quick summary of how to use it:\n\n\nCode\n%pip install optuna\n\n\n\nimport optuna\n# to supress unnecessary output as it prints quite a lot by default\noptuna.logging.set_verbosity(optuna.logging.WARNING) \n\n# Task: with 100 trials find a minimum for a function (x-10)**2\n\n# objective function to minimize\ndef objective(trial):\n    # this is just returning float and internally in the trial optuna \n    # keeps track of all the values used\n    x = trial.suggest_float(\"x\", -100, 100) \n    return (x - 10)**2\n\n# create optimization object that will keep track of the whole process\nstudy = optuna.create_study() \n\n# and run optimization with 100 runs\nstudy.optimize(objective, n_trials=100)\n\n# get the optimized values\nstudy.best_params['x'] # we are pretty close\n\n10.108796067394927\n\n\n\n# however it won't do magic if you don't give it enough \"space\"\n# here if you give it just 10 trials, it will usually miss quite \n# substantially\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -100, 100)\n    return (x - 10)**2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nstudy.best_params['x'] # ... it is usually not so good\n\n-10.114148942248292\n\n\nhow optuna works internally is quite simple but ingenious: each call to trial.suggest_*() function already returns a python variable, so you can use it in your code straight away:\n\nstudy = optuna.create_study()\ndef objective(trial):\n    # trial.suggest_int returns integer - all the magic of storing\n    # what value was used in a specific trial is recorded in trial object\n    i = trial.suggest_int('x', 0, 100, step=10)\n    print(f\"next {i=}\")\n    return i\n\nstudy.optimize(objective, n_trials=10)\nstudy.best_params['x']\n\nnext i=0\nnext i=0\nnext i=90\nnext i=60\nnext i=70\nnext i=10\nnext i=10\nnext i=10\nnext i=60\nnext i=90\n\n\n0\n\n\nIt is interesting at first how the numbers are drawn from the space - this is all quasi random and duplicates are possible. Especially if we have very limited space of available unique values as in here. This is not an implementation bug - here we deal with a single variable, but if we have multiple ones, it quite makes sense to try simillar values if we variate other parameters at the same time. This is default, but you can choose different strategires for drawing values.\n\n\n\n\n\n# however with 10 trials...\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -100, 100)\n    return (x - 10)**2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nprint(f\"After 10 trials we got {study.best_params['x']=:.2f}\") # ... it is usually not so good\n\n# but training for another 10 iterations does the trick\nstudy.optimize(objective, n_trials=10)\n\nprint(f\"... but 10 more runs get us closer {study.best_params['x']=:.2f}\") # ok, now it is better :)\n\nAfter 10 trials we got study.best_params['x']=1.35\n... but 10 more runs get us closer study.best_params['x']=9.38\n\n\n\n\n\nOr just run hiperparameter searches when your colab disconnects\nOptuna allows for distrubuted trials\n\n#straight from optuna docs @ https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -10, 10)\n    return (x - 2) ** 2\n\n\nif __name__ == \"__main__\":\n    study = optuna.load_study(\n        study_name=\"distributed-example\", storage=\"mysql://root@localhost/example\"\n    )\n    study.optimize(objective, n_trials=100)\n\n\n\n\nIt was a bit tricky to understand for me how it works, as it is usually hidden in handlers to specific libraries. But here is a clear example that doesn’t hide anything from you:\n\noptuna.logging.set_verbosity(optuna.logging.INFO)\nimport random\n\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -10, 10) # you draw next value\n\n    # and this is an inner loop simulating inner loop in the \n    # optimization functions, like going through batches in\n    # NN training\n    for i in reversed(range(10)): \n        # here we just make up a number simulating intermediate result\n        # that is sent to optuna to validate if it is worth continuing\n        made_up_intermediate_value = random.randint(1, 10)\n        # it is reported to optuna\n        trial.report(made_up_intermediate_value, i)\n\n        # Handle pruning based on the intermediate value.\n        if trial.should_prune(): # Optuna suggests to prune?\n            print(f'''\\\nPruning trial {trial.number} with value {made_up_intermediate_value=}\\n\\\nbecause it is already less optimal than previously recorded best value''', flush=True, end='')\n            # if yes we throw exception that is handled by `optimize` method\n            # in optuna\n            raise optuna.TrialPruned() \n\n\n\n    return (x - 2) ** 2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\nstudy.best_params['x']\n\n[I 2023-01-13 13:49:05,151] A new study created in memory with name: no-name-826daad7-a560-4139-8012-384a08aecae9\n[I 2023-01-13 13:49:05,154] Trial 0 finished with value: 27.811950820406743 and parameters: {'x': 7.2737037099562905}. Best is trial 0 with value: 27.811950820406743.\n[I 2023-01-13 13:49:05,157] Trial 1 finished with value: 81.56034995467249 and parameters: {'x': -7.0310768989458}. Best is trial 0 with value: 27.811950820406743.\n[I 2023-01-13 13:49:05,162] Trial 2 finished with value: 1.8078821300442816 and parameters: {'x': 3.3445750741569924}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,165] Trial 3 finished with value: 51.599347421072665 and parameters: {'x': 9.183268575034116}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,168] Trial 4 finished with value: 87.26649837508509 and parameters: {'x': -7.341653942160622}. Best is trial 2 with value: 1.8078821300442816.\n\n\nPruning trial 5 with value made_up_intermediate_value=10\nbecause it is already less optimal than previously recorded best value\n\n\n[I 2023-01-13 13:49:05,170] Trial 5 pruned. \n[I 2023-01-13 13:49:05,181] Trial 6 finished with value: 26.47065704510398 and parameters: {'x': -3.1449642413824392}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,185] Trial 7 finished with value: 29.163269432320956 and parameters: {'x': 7.400302716729957}. Best is trial 2 with value: 1.8078821300442816.\n\n\nPruning trial 8 with value made_up_intermediate_value=6\nbecause it is already less optimal than previously recorded best value\n\n\n[I 2023-01-13 13:49:05,187] Trial 8 pruned. \n[I 2023-01-13 13:49:05,194] Trial 9 finished with value: 38.838470030340275 and parameters: {'x': 8.232051831486984}. Best is trial 2 with value: 1.8078821300442816.\n\n\n3.3445750741569924"
  },
  {
    "objectID": "posts/math_resources/index.html",
    "href": "posts/math_resources/index.html",
    "title": "Math resources",
    "section": "",
    "text": "My Uni days are long gone, I was reasonably good at math, but over the years of not using it, I almost feel like the knowledge was never there.\nHere is my journey through the process of remembering some math that I need to feel more comfortable with for the basics of deep learning and to be able to digest papers in the broad area of deep learning research.\nAdvice to my former self: First read some papers, struggle through them, let the frustration build up so you have a motivation to learn + you will also build an intuition of what tools you may actually need!\nAs for the resouces, I started with Deep Learninig book few years ago, but got discouraged by the theory and I didn’t have enough practice to know that it will be useful some day.\nRecently I found out that there is a growing comunity of people around that book led by Sanyam Buthani. Apart from the community and help + motivation to learn that comes with it, there are number of resources for self study, such as notebooks with all the concepts translated into code, which makes it so much more practical.\nStaying around the same book, there are great lectures going through each chapter of that book.\nIf you want to learn more about torch.autograd, frameworks that do automatic differentiation in general and understand calculus that is the engine of deep learning machine there is an excelent The Matrix Calculus You Need For Deep Learning.\nAnother interesting resources are Mathematics for Machine Learning and short lectures covering pretty much all you need for the topic in a very accessible, visual and short form.\nLast but not least, Andrew Ng’s advice on how to read a paper which I also sumarize here!\nAll these resources are freely available online."
  },
  {
    "objectID": "posts/nerf_basics/index.html",
    "href": "posts/nerf_basics/index.html",
    "title": "NeRF basics",
    "section": "",
    "text": "This is a companion blog post for my presentation given at Data Science Summit 2023 in Warsaw.\nThe presentation itself is on google docs"
  },
  {
    "objectID": "posts/f_cross_entropy/index.html",
    "href": "posts/f_cross_entropy/index.html",
    "title": "Why use F.cross_entropy?",
    "section": "",
    "text": "apart from less code of course! Another reason: it is safer!\nI like to have more controll over what and how I am doing things, instead of using black boxes. But be warned that you can get burned when computing negative log likelihood yourself (the same is tru for softmaxes for example).\nsee this example:\n\nimport torch\n\nlogits = torch.tensor([-100, -5, 2, 100])\nlogits = logits.exp()\nprobs = logits / logits.sum()\nprobs, probs.sum()\n\n(tensor([0., 0., 0., nan]), tensor(nan))\n\n\nmakes sense, right? exp(100) is VERY large, so if your network misbehaves and produces extreme activations, you have a problem, but…\n\nimport torch\n\nlogits = torch.tensor([-100, -5, 2, 100])\n\n# here we deduct max value from the logits, so everyting is in (-∞, 0)\n#----------------------\nlogits -= logits.max() \n#----------------------\n\nlogits = logits.exp()\nprobs = logits / logits.sum()\nprobs, probs.sum()\n\n(tensor([0.0000e+00, 0.0000e+00, 2.7465e-43, 1.0000e+00]), tensor(1.))\n\n\nis working nicely, and that’s what F.cross_entropy does internally. Of course, you can always add that normalization to safeguard against such cases (or add batchnorm layers to your architecture if you don’t wan’t to bother about such cases at the cost of a little more complexity and state in your model).\nPlus of course I am sure there are also more good computational efficiency reasons to use torch’es built-in method do that."
  },
  {
    "objectID": "example_posts/post-with-code/index.html",
    "href": "example_posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "example_posts/welcome/index.html",
    "href": "example_posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Technical notes",
    "section": "",
    "text": "NeRF basics\n\n\n\n\n\n\n\nnerf\n\n\n\n\ncompanion post for DSS 2023 conference\n\n\n\n\n\n\nNov 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTraining vision models on synthetic images\n\n\n\n\n\n\n\npaper review\n\n\nvision\n\n\n\n\nNot SOTA performance, but quite good\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWhy use F.cross_entropy?\n\n\n\n\n\n\n\ntraining\n\n\n\n\n… instead of computing it yourself?\n\n\n\n\n\n\nJan 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nOptuna is hot on Kaggle\n\n\n\n\n\n\n\ntraining\n\n\n\n\nHow to use it with code examples\n\n\n\n\n\n\nDec 22, 2022\n\n\n\n\n\n\n  \n\n\n\n\nHow to read papers?\n\n\n\n\n\n\n\npaper review\n\n\n\n\nGreat advice from Andrew Ng\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMath resources\n\n\n\n\n\n\n\nmath\n\n\n\n\nAll you need to within weeks understand Deep Learning and be reasonably comfortable with papers.\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\nNo matching items"
  }
]