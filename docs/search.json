[
  {
    "objectID": "posts/new_programming_paradigm.html",
    "href": "posts/new_programming_paradigm.html",
    "title": "Michał Pawłowski",
    "section": "",
    "text": "Software 2.0 as a new programming paradigm.\n\n- for certain class of problems\n- compexity\n- bias in data\n\nsee https://www.youtube.com/watch?v=orY5aLMDU-I"
  },
  {
    "objectID": "posts/how_to_read_papers/index.html",
    "href": "posts/how_to_read_papers/index.html",
    "title": "How to read papers?",
    "section": "",
    "text": "Andrew Ng gave an career advice lecture at Stanford in 2019 where he also mentioned how to read academic papers.\nRead it taking multiple passes through the paper:\n\nTitle + Abstract + Figures\nIntro + Conclusions + Figures + Skim rest\nRead text but skip math\nRead all of it but skip what doesn’t make sense\n\nwhich boils down to:\nGo from efficient and high information content first and dig into the harder bits gradually\nSome of the questions to keep in mind during the process (and to decide whether to go to the next step):\n\nWhat did authors try to acomplish?\nWhat are the key elements of the approach?\nWhat can you use yourself?\nWhat other references do you want to follow?\n\nIt is worth watching, as it also sumarizes the process of creating and reviewing the paper to give rationale for that process."
  },
  {
    "objectID": "posts/optuna_notes/index.html",
    "href": "posts/optuna_notes/index.html",
    "title": "Optuna is hot on Kaggle",
    "section": "",
    "text": "While doing HF RL course I bumped into Optuna, then I’ve noticed that ppl do it on Kaggle a lot - this is like a badge of honor for a package if it is being used on a top ML competition site ergo it is worth learning!\nSome vocab to get started:\n\nobjective(trial) function - function to optimize\ntrial - a single test, also an object passed to the objective function\nstudy - a set of trial at the end of which you get a suggestion of parameters to use\nparameter - parameter to optimize\nsetting initial values for parameters to optimize:\n\noptuna.trial.Trial.suggest_categeorical(‘name’, [‘list’])\noptuna.trial.Trial.suggest_int(‘name’, min, max)\noptuna.trial.Trial.suggest_float(‘name’, min, max)\n\n\nHere is a quick summary of how to use it:\n\n\nCode\n%pip install optuna\n\n\n\nimport optuna\n# to supress unnecessary output as it prints quite a lot by default\noptuna.logging.set_verbosity(optuna.logging.WARNING) \n\n# Task: with 100 trials find a minimum for a function (x-10)**2\n\n# objective function to minimize\ndef objective(trial):\n    # this is just returning float and internally in the trial optuna \n    # keeps track of all the values used\n    x = trial.suggest_float(\"x\", -100, 100) \n    return (x - 10)**2\n\n# create optimization object that will keep track of the whole process\nstudy = optuna.create_study() \n\n# and run optimization with 100 runs\nstudy.optimize(objective, n_trials=100)\n\n# get the optimized values\nstudy.best_params['x'] # we are pretty close\n\n10.108796067394927\n\n\n\n# however it won't do magic if you don't give it enough \"space\"\n# here if you give it just 10 trials, it will usually miss quite \n# substantially\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -100, 100)\n    return (x - 10)**2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nstudy.best_params['x'] # ... it is usually not so good\n\n-10.114148942248292\n\n\nhow optuna works internally is quite simple but ingenious: each call to trial.suggest_*() function already returns a python variable, so you can use it in your code straight away:\n\nstudy = optuna.create_study()\ndef objective(trial):\n    # trial.suggest_int returns integer - all the magic of storing\n    # what value was used in a specific trial is recorded in trial object\n    i = trial.suggest_int('x', 0, 100, step=10)\n    print(f\"next {i=}\")\n    return i\n\nstudy.optimize(objective, n_trials=10)\nstudy.best_params['x']\n\nnext i=0\nnext i=0\nnext i=90\nnext i=60\nnext i=70\nnext i=10\nnext i=10\nnext i=10\nnext i=60\nnext i=90\n\n\n0\n\n\nIt is interesting at first how the numbers are drawn from the space - this is all quasi random and duplicates are possible. Especially if we have very limited space of available unique values as in here. This is not an implementation bug - here we deal with a single variable, but if we have multiple ones, it quite makes sense to try simillar values if we variate other parameters at the same time. This is default, but you can choose different strategires for drawing values.\n\n\n\n\n\n# however with 10 trials...\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -100, 100)\n    return (x - 10)**2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nprint(f\"After 10 trials we got {study.best_params['x']=:.2f}\") # ... it is usually not so good\n\n# but training for another 10 iterations does the trick\nstudy.optimize(objective, n_trials=10)\n\nprint(f\"... but 10 more runs get us closer {study.best_params['x']=:.2f}\") # ok, now it is better :)\n\nAfter 10 trials we got study.best_params['x']=1.35\n... but 10 more runs get us closer study.best_params['x']=9.38\n\n\n\n\n\nOr just run hiperparameter searches when your colab disconnects\nOptuna allows for distrubuted trials\n\n#straight from optuna docs @ https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -10, 10)\n    return (x - 2) ** 2\n\n\nif __name__ == \"__main__\":\n    study = optuna.load_study(\n        study_name=\"distributed-example\", storage=\"mysql://root@localhost/example\"\n    )\n    study.optimize(objective, n_trials=100)\n\n\n\n\nIt was a bit tricky to understand for me how it works, as it is usually hidden in handlers to specific libraries. But here is a clear example that doesn’t hide anything from you:\n\noptuna.logging.set_verbosity(optuna.logging.INFO)\nimport random\n\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -10, 10) # you draw next value\n\n    # and this is an inner loop simulating inner loop in the \n    # optimization functions, like going through batches in\n    # NN training\n    for i in reversed(range(10)): \n        # here we just make up a number simulating intermediate result\n        # that is sent to optuna to validate if it is worth continuing\n        made_up_intermediate_value = random.randint(1, 10)\n        # it is reported to optuna\n        trial.report(made_up_intermediate_value, i)\n\n        # Handle pruning based on the intermediate value.\n        if trial.should_prune(): # Optuna suggests to prune?\n            print(f'''\\\nPruning trial {trial.number} with value {made_up_intermediate_value=}\\n\\\nbecause it is already less optimal than previously recorded best value''', flush=True, end='')\n            # if yes we throw exception that is handled by `optimize` method\n            # in optuna\n            raise optuna.TrialPruned() \n\n\n\n    return (x - 2) ** 2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\nstudy.best_params['x']\n\n[I 2023-01-13 13:49:05,151] A new study created in memory with name: no-name-826daad7-a560-4139-8012-384a08aecae9\n[I 2023-01-13 13:49:05,154] Trial 0 finished with value: 27.811950820406743 and parameters: {'x': 7.2737037099562905}. Best is trial 0 with value: 27.811950820406743.\n[I 2023-01-13 13:49:05,157] Trial 1 finished with value: 81.56034995467249 and parameters: {'x': -7.0310768989458}. Best is trial 0 with value: 27.811950820406743.\n[I 2023-01-13 13:49:05,162] Trial 2 finished with value: 1.8078821300442816 and parameters: {'x': 3.3445750741569924}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,165] Trial 3 finished with value: 51.599347421072665 and parameters: {'x': 9.183268575034116}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,168] Trial 4 finished with value: 87.26649837508509 and parameters: {'x': -7.341653942160622}. Best is trial 2 with value: 1.8078821300442816.\n\n\nPruning trial 5 with value made_up_intermediate_value=10\nbecause it is already less optimal than previously recorded best value\n\n\n[I 2023-01-13 13:49:05,170] Trial 5 pruned. \n[I 2023-01-13 13:49:05,181] Trial 6 finished with value: 26.47065704510398 and parameters: {'x': -3.1449642413824392}. Best is trial 2 with value: 1.8078821300442816.\n[I 2023-01-13 13:49:05,185] Trial 7 finished with value: 29.163269432320956 and parameters: {'x': 7.400302716729957}. Best is trial 2 with value: 1.8078821300442816.\n\n\nPruning trial 8 with value made_up_intermediate_value=6\nbecause it is already less optimal than previously recorded best value\n\n\n[I 2023-01-13 13:49:05,187] Trial 8 pruned. \n[I 2023-01-13 13:49:05,194] Trial 9 finished with value: 38.838470030340275 and parameters: {'x': 8.232051831486984}. Best is trial 2 with value: 1.8078821300442816.\n\n\n3.3445750741569924"
  },
  {
    "objectID": "posts/math_resources/index.html",
    "href": "posts/math_resources/index.html",
    "title": "Math resources",
    "section": "",
    "text": "My Uni days are long gone, I was reasonably good at math, but over the years of not using it, I almost feel like the knowledge was never there.\nHere is my journey through the process of remembering some math that I need to feel more comfortable with for the basics of deep learning and to be able to digest papers in the broad area of deep learning research.\nAdvice to my former self: First read some papers, struggle through them, let the frustration build up so you have a motivation to learn + you will also build an intuition of what tools you may actually need!\nAs for the resouces, I started with Deep Learninig book few years ago, but got discouraged by the theory and I didn’t have enough practice to know that it will be useful some day.\nRecently I found out that there is a growing comunity of people around that book led by Sanyam Buthani. Apart from the community and help + motivation to learn that comes with it, there are number of resources for self study, such as notebooks with all the concepts translated into code, which makes it so much more practical.\nStaying around the same book, there are great lectures going through each chapter of that book.\nIf you want to learn more about torch.autograd, frameworks that do automatic differentiation in general and understand calculus that is the engine of deep learning machine there is an excelent The Matrix Calculus You Need For Deep Learning.\nAnother interesting resources are Mathematics for Machine Learning and short lectures covering pretty much all you need for the topic in a very accessible, visual and short form.\nLast but not least, Andrew Ng’s advice on how to read a paper which I also sumarize here!\nAll these resources are freely available online."
  },
  {
    "objectID": "posts/f_cross_entropy/f_cross_entropy.html",
    "href": "posts/f_cross_entropy/f_cross_entropy.html",
    "title": "Why use F.cross_entropy",
    "section": "",
    "text": "apart from less code of course! Another reason: it is safer!\nI like to have more controll over what and how I am doing things, instead of using black boxes. But be warned that you can get burned when computing negative log likelihood yourself (the same is tru for softmaxes for example).\nsee this example:\n\nimport torch\n\nlogits = torch.tensor([-100, -5, 2, 100])\nlogits = logits.exp()\nprobs = logits / logits.sum()\nprobs, probs.sum()\n\n(tensor([0., 0., 0., nan]), tensor(nan))\n\n\nmakes sense, right? exp(100) is VERY large, so if your network misbehaves and produces extreme activations, you have a problem, but…\n\nimport torch\n\nlogits = torch.tensor([-100, -5, 2, 100])\n\n# here we deduct max value from the logits, so everyting is in (-∞, 0)\n#----------------------\nlogits -= logits.max() \n#----------------------\n\nlogits = logits.exp()\nprobs = logits / logits.sum()\nprobs, probs.sum()\n\n(tensor([0.0000e+00, 0.0000e+00, 2.7465e-43, 1.0000e+00]), tensor(1.))\n\n\nis working nicely, and that’s what F.cross_entropy does internally. Of course, you can always add that normalization to safeguard against such cases (or add batchnorm layers to your architecture if you don’t wan’t to bother about such cases at the cost of a little more complexity and state in your model).\nPlus of course I am sure there are also more good computational efficiency reasons to use torch’es built-in method do that."
  },
  {
    "objectID": "example_posts/post-with-code/index.html",
    "href": "example_posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "example_posts/welcome/index.html",
    "href": "example_posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Technical notes",
    "section": "",
    "text": "Why use F.cross_entropy\n\n\ninstead of computing it yourself?\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nOptuna is hot on Kaggle\n\n\n\n\n\nHow to use it with code examples\n\n\n\n\n\n\nDec 22, 2022\n\n\n\n\n\n\n  \n\n\n\n\nHow to read papers?\n\n\nadvice from Andrew Ng\n\n\n\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMath resources\n\n\nto understand Deep Learning and be reasonably comfortable with papers.\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Husband, father, Christian, programmer, fascinated with NN.\nI took a sabbatical to explore machine/deep learning but I am OPEN for OFFERS that will lead me into direction of greater enlightement in a field of deep models. Especially interested in do good fields: medicine, pharma, climate etc.\nCurriculum Vitae\nAll images dreamt by Stable Diffusion, but I promise no ChatGPT content!"
  }
]