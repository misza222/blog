{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Optuna\"\n",
    "subtitle: \"is hot on Kaggle\"\n",
    "format: html\n",
    "date: \"12/22/2022\"\n",
    "image: optimization.jpeg\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna - the choice of Kagglers\n",
    "\n",
    "While doing [HF RL course](https://huggingface.co/deep-rl-course/) I bumped into [Optuna](https://optuna.readthedocs.io/en/stable/index.html), then I've noticed that ppl do it on Kaggle a lot - this is like a badge of honor for a package if it is being used on a top ML competition site *ergo* it is worth learning!\n",
    "\n",
    "Some vocab to get started:\n",
    "\n",
    "- `objective(trial)` function - function to optimize\n",
    "- trial - a single test, also an object passed to the objective function \n",
    "- study - a set of trial at the end of which you get a suggestion of parameters to use\n",
    "- parameter - parameter to optimize\n",
    "- setting initial values for parameters to optimize:\n",
    "  * optuna.trial.Trial.suggest_categeorical('name', ['list'])\n",
    "  * optuna.trial.Trial.suggest_int('name', min, max)\n",
    "  * optuna.trial.Trial.suggest_float('name', min, max)\n",
    "   \n",
    "\n",
    "Here is a quick summary of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| output: false\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.108796067394927"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "# to supress unnecessary output as it prints quite a lot by default\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "\n",
    "# Task: with 100 trials find a minimum for a function (x-10)**2\n",
    "\n",
    "# objective function to minimize\n",
    "def objective(trial):\n",
    "    # this is just returning float and internally in the trial optuna \n",
    "    # keeps track of all the values used\n",
    "    x = trial.suggest_float(\"x\", -100, 100) \n",
    "    return (x - 10)**2\n",
    "\n",
    "# create optimization object that will keep track of the whole process\n",
    "study = optuna.create_study() \n",
    "\n",
    "# and run optimization with 100 runs\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# get the optimized values\n",
    "study.best_params['x'] # we are pretty close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.114148942248292"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# however it won't do magic if you don't give it enough \"space\"\n",
    "# here if you give it just 10 trials, it will usually miss quite \n",
    "# substantially\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -100, 100)\n",
    "    return (x - 10)**2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "study.best_params['x'] # ... it is usually not so good"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how optuna works internally is quite simple but ingenious: each call to `trial.suggest_*()` function already returns a python variable, so you can use it in your code straight away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next i=0\n",
      "next i=0\n",
      "next i=90\n",
      "next i=60\n",
      "next i=70\n",
      "next i=10\n",
      "next i=10\n",
      "next i=10\n",
      "next i=60\n",
      "next i=90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "def objective(trial):\n",
    "    # trial.suggest_int returns integer - all the magic of storing\n",
    "    # what value was used in a specific trial is recorded in trial object\n",
    "    i = trial.suggest_int('x', 0, 100, step=10)\n",
    "    print(f\"next {i=}\")\n",
    "    return i\n",
    "\n",
    "study.optimize(objective, n_trials=10)\n",
    "study.best_params['x']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting at first how the numbers are drawn from the space - this is all quasi random and duplicates are possible. Especially if we have very limited space of available unique values as in here. This is not an implementation bug - here we deal with a single variable, but if we have multiple ones, it quite makes sense to try simillar values if we variate other parameters at the same time. This is default, but you can choose different [strategires for drawing values](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html#sampling-algorithms)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful tricks!\n",
    "\n",
    "#### Continue the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 10 trials we got study.best_params['x']=1.35\n",
      "... but 10 more runs get us closer study.best_params['x']=9.38\n"
     ]
    }
   ],
   "source": [
    "# however with 10 trials...\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -100, 100)\n",
    "    return (x - 10)**2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(f\"After 10 trials we got {study.best_params['x']=:.2f}\") # ... it is usually not so good\n",
    "\n",
    "# but training for another 10 iterations does the trick\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(f\"... but 10 more runs get us closer {study.best_params['x']=:.2f}\") # ok, now it is better :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a db to tune on multiple machines\n",
    "\n",
    "Or just run hiperparameter searches when your colab disconnects\n",
    "\n",
    "Optuna allows for distrubuted trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#straight from optuna docs @ https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.load_study(\n",
    "        study_name=\"distributed-example\", storage=\"mysql://root@localhost/example\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early trial stopping (vel *pruning* in Optuna's terms)\n",
    "\n",
    "It was a bit tricky to understand for me how it works, as it is usually hidden in handlers to specific libraries. But here is a clear example that doesn't hide anything from you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-13 13:49:05,151]\u001b[0m A new study created in memory with name: no-name-826daad7-a560-4139-8012-384a08aecae9\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,154]\u001b[0m Trial 0 finished with value: 27.811950820406743 and parameters: {'x': 7.2737037099562905}. Best is trial 0 with value: 27.811950820406743.\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,157]\u001b[0m Trial 1 finished with value: 81.56034995467249 and parameters: {'x': -7.0310768989458}. Best is trial 0 with value: 27.811950820406743.\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,162]\u001b[0m Trial 2 finished with value: 1.8078821300442816 and parameters: {'x': 3.3445750741569924}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,165]\u001b[0m Trial 3 finished with value: 51.599347421072665 and parameters: {'x': 9.183268575034116}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,168]\u001b[0m Trial 4 finished with value: 87.26649837508509 and parameters: {'x': -7.341653942160622}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning trial 5 with value made_up_intermediate_value=10\n",
      "because it is already less optimal than previously recorded best value"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-13 13:49:05,170]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,181]\u001b[0m Trial 6 finished with value: 26.47065704510398 and parameters: {'x': -3.1449642413824392}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,185]\u001b[0m Trial 7 finished with value: 29.163269432320956 and parameters: {'x': 7.400302716729957}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning trial 8 with value made_up_intermediate_value=6\n",
      "because it is already less optimal than previously recorded best value"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-13 13:49:05,187]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-13 13:49:05,194]\u001b[0m Trial 9 finished with value: 38.838470030340275 and parameters: {'x': 8.232051831486984}. Best is trial 2 with value: 1.8078821300442816.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3445750741569924"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "import random\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10) # you draw next value\n",
    "\n",
    "    # and this is an inner loop simulating inner loop in the \n",
    "    # optimization functions, like going through batches in\n",
    "    # NN training\n",
    "    for i in reversed(range(10)): \n",
    "        # here we just make up a number simulating intermediate result\n",
    "        # that is sent to optuna to validate if it is worth continuing\n",
    "        made_up_intermediate_value = random.randint(1, 10)\n",
    "        # it is reported to optuna\n",
    "        trial.report(made_up_intermediate_value, i)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune(): # Optuna suggests to prune?\n",
    "            print(f'''\\\n",
    "Pruning trial {trial.number} with value {made_up_intermediate_value=}\\n\\\n",
    "because it is already less optimal than previously recorded best value''', flush=True, end='')\n",
    "            # if yes we throw exception that is handled by `optimize` method\n",
    "            # in optuna\n",
    "            raise optuna.TrialPruned() \n",
    "\n",
    "\n",
    "\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)\n",
    "study.best_params['x']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdaea57c0b9010ea74c77e884f0f49a414be4bd0fcb5deeb3a8fb91359695020"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
