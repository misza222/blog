{"title":"Math resources","markdown":{"yaml":{"title":"Math resources","subtitle":"to understand Deep Learning and be reasonably comfortable with papers.","format":"html"},"containsRefs":false,"markdown":"\n\nMy Uni days are long gone, I was reasonably good at math, but over the years of not using it, I almost feel like the knowledge was never there. \n\nHere is my journey through the process of remembering some math that I need to feel more comfortable with for the basics of deep learning and to be able to digest papers in the broad area of deep learning research.\n\nAdvice to my former self: First read some papers, struggle through them, let the frustration build up so you have a motivation to learn + you will also build an intuition of what tools you may actually need!\n\nAs for the resouces, I started with [Deep Learninig](https://www.deeplearningbook.org/) book few years ago, but got discouraged by the theory and I didn't have enough practice to know that it will be useful some day.\n\nRecently I found out that there is a growing comunity of people around that book led by [Sanyam Buthani](https://twitter.com/bhutanisanyam1/status/1600167351319924736) (SHOW TWEET instead). Apart from the community and help + motivation to learn that comes with it, there are number of resources for self study, such as [notebooks](https://github.com/init27/Deep-Learning-Book-Supplementary-Materials/) with all the concepts translated into code, which makes it so much more practical.\n\nStaying around the same book, there are [great lectures](https://www.youtube.com/playlist?list=PLsXu9MHQGs8df5A4PzQGw-kfviylC-R9b) going through each chapter of that book.\n\nIf you want to learn more about [torch.autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html), frameworks that do automatic differentiation in general and understand calculus that is the engine of deep learning machine there is an excelent [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/index.html).\n\nAnother interesting resources are [Mathematics for Machine Learning](https://mml-book.com) and [short lectures](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) covering pretty much all you need for the topic in a very accessible, visual and short form.\n\nLast but not least, Andrew Ng's advice on [how to read a paper](https://www.youtube.com/watch?v=733m6qBH-jI&t=486s) which I also sumarize [here](how_to_read_an_academic_paper.html)!\n\nAll these resources are freely available online.\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"math_resources.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","theme":"litera","title-block-banner":true,"title":"Math resources","subtitle":"to understand Deep Learning and be reasonably comfortable with papers."},"extensions":{"book":{"multiFile":true}}}}}